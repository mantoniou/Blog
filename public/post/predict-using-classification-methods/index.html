<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		 
			
  
    <meta name="twitter:card" content="summary"/>
    
      <meta name="twitter:image" content="/images/avatar.png" />
    
  
  
  <meta name="twitter:title" content="Predict using classification methods"/>
  <meta name="twitter:description" content="[Feb 19, 2018] Build a model that will predict whether a tumor is malignant or benign, based on data from a study on breast cancer."/>
  
    <meta name="twitter:site" content="@your_twitter_id"/>
  
  
  
  
    <meta name="twitter:creator" content="@"/>
  



		
		
		<meta name="description" content="Site Description">
		<meta name="generator" content="Hugo 0.36.1" />
		<title>Predict using classification methods &middot; Manos Antoniou</title>
		<link rel="shortcut icon" href="/images/favicon.ico">
		<link rel="stylesheet" href="/css/style.css">
		<link rel="stylesheet" href="/css/highlight.css">

		
		<link rel="stylesheet" href="/css/font-awesome.min.css">
		

		
		<link href="/index.xml" rel="alternate" type="application/rss+xml" title="Manos Antoniou" />
		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='/'> <span class="arrow">←</span>Home</a>
	
	<a href='/about'>About</a>
	<a href='/tags'>Tags</a>
	<a href='https://www.linkedin.com/in/manos-antoniou-a558001b/'>LinkedIn</a>


	

	
	<a class="cta" href="/index.xml">Subscribe</a>
	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        Predict using classification methods
                    </h1>
                    <h2 class="headline">
                    Feb 19, 2018 00:00
                    · 2753 words
                    · 13 minute read
                      <span class="tags">
                      
                      
                          
                              <a href="/tags/classification">classification</a>
                          
                              <a href="/tags/decision-trees">Decision trees</a>
                          
                              <a href="/tags/logistic-regression">Logistic regression</a>
                          
                              <a href="/tags/clustering">clustering</a>
                          
                      
                      
                      </span>
                    </h2>
                </header>
                
                  
                
                <section id="post-body">
                    <p>In this analysis i’ll try to build a model that will predict whether a tumor is malignant or benign, based on data from a study on breast cancer. Classification algorithms will be used in the modelling process.</p>
<p><em>The dataset</em></p>
<p>The data for this analysis refer to 569 patients from a study on breast cancer. The actual data can be found at UCI (Machine Learning Repository): <a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)" class="uri">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)</a>. The variables were computed from a digitized image of a breast mass and describe characteristics of the cell nucleus present in the image. In particular the variables are the following</p>
<ol style="list-style-type: lower-alpha">
<li>radius (mean of distances from center to points on the perimeter)</li>
<li>texture (standard deviation of gray-scale values)</li>
<li>perimeter</li>
<li>area</li>
<li>smoothness (local variation in radius lengths)</li>
<li>compactness (perimeter^2 / area - 1.0)</li>
<li>concavity (severity of concave portions of the contour)</li>
<li>concave points (number of concave portions of the contour)</li>
<li>symmetry</li>
<li>fractal dimension (“coastline approximation” - 1)</li>
<li>type (tumor can be either malignant -M- or benign -B-)</li>
</ol>
<pre class="r"><code># Load Libraries
library(dplyr)
library(tidyr)
library(xda)
library(corrgram)
library(ggplot2)
library(ggthemes)
library(cluster)
library(caret)

# Insert dataset into R
med &lt;- read.table(&quot;/Users/manos/Dropbox/Projects/R/Blogdown/data/cancer.txt&quot;, sep=&quot;,&quot;, header = TRUE)


# Discard the id column as it will not be used in any of the analysis below 
med &lt;- med[, 2:12]

# change the name of the first column to diagnosis
colnames(med)[1] &lt;- &quot;diagnosis&quot;</code></pre>
<div id="exploratory-analysis" class="section level2">
<h2>Exploratory Analysis</h2>
<p>It is essential to have an overview of the dataset. Below there is a box-plot of each predictor against the target variable (tumor). The log value of the predictors used instead of the actual values, for a better view of the plot.</p>
<pre class="r"><code># Create a long version of the dataset
med2 &lt;- gather(med, &quot;feature&quot;, &quot;n&quot;, 2:11)

ggplot(med2)+
  geom_boxplot(aes(diagnosis, log(n)))+
  facet_wrap(~feature, scales = &quot;free&quot;)+
  labs(title = &quot;Box-plot of all predictors(log scaled) per tumor type&quot;, 
       subtitle = &quot;tumor can be either malignant -M- or benign -B-&quot;)+
 theme_fivethirtyeight()+
  theme(axis.title = element_text()) + 
  ylab(&quot;Predictor&#39;s log value&quot;) + 
  xlab(&#39;&#39;)</code></pre>
<p><img src="/post/2018-02-19-predict-using-classification-methods_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>It seems that for most predictors the malignant level of tumor type has higher values than the benign level.</p>
<p>Now let’s see if the predictors are correlated. Below there is a scatter-plot matrix of all predictors.</p>
<pre class="r"><code># Scatterplot matrix of all numeric variables
pairs(~., data = med[, sapply(med, is.numeric)], main = &quot;Scatterplot Matrix of variables&quot;)</code></pre>
<p><img src="/post/2018-02-19-predict-using-classification-methods_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We can see that there are some predictors that are strongly related, as expected, such as radius, perimeter &amp; area.</p>
<p>A correlogram will serve us better and quantify all correlations.</p>
<pre class="r"><code>library(corrplot)

# Plot correlogram of numeric variables
corrplot(cor(med[,2:11]), type=&quot;lower&quot;, tl.srt = 90)</code></pre>
<p><img src="/post/2018-02-19-predict-using-classification-methods_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>We can spot some less significant correlations, such as concave &amp; concativity &amp; compactness. Also concave against radius, perimeter &amp; area.</p>
</div>
<div id="predicting-using-classification-methods" class="section level2">
<h2>Predicting using classification methods</h2>
<p>In the first part of this analysis, the goal is to predict whether the tumor is malignant or benign based on the variables produced by the digitized image using classification methods. Classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.</p>
<p>So we must develop a model that classifies (categorize) each tumor (case) to either malignant or benign.</p>
<p>Classification performed with 2 different methods, <em>Logistic Regression</em> and <em>Decision Trees</em>.</p>
<div id="feature-selection" class="section level3">
<h3>Feature selection</h3>
<p>It is important to use only significant predictors while building the prediction model. You don’t need to use every feature at your disposal for creating an algorithm. You can assist the algorithm by feeding in only those features that are really important. Below there are some reasons for this:</p>
<ul>
<li>It enables the machine learning algorithm to train faster.<br />
</li>
<li>It reduces the complexity of a model and makes it easier to interpret.<br />
</li>
<li>It improves the accuracy of a model if the right subset is chosen.<br />
</li>
<li>It reduces over-fitting.</li>
</ul>
<p>In particular, i used the stepwise (forward &amp; backward) logistic regression on the data, since the dataset is small. This method is computationally very expensive, so it is not recommended for very large datasets.</p>
<pre class="r"><code>library(MASS)

# Create a logistic regression model
glm &lt;- glm(diagnosis ~ ., family=binomial(link=&#39;logit&#39;), data = med)

# Run the stepwise regression
both &lt;- stepAIC(glm, direction = &quot;both&quot;)</code></pre>
<pre><code>## Start:  AIC=168.13
## diagnosis ~ radius + texture + perimeter + area + smoothness + 
##     compactness + concavity + concave + symmetry + fractal
## 
##               Df Deviance    AIC
## - compactness  1   146.14 166.14
## - perimeter    1   146.15 166.15
## - radius       1   146.44 166.44
## - fractal      1   146.78 166.78
## - concavity    1   147.23 167.23
## &lt;none&gt;             146.13 168.13
## - symmetry     1   148.44 168.44
## - area         1   151.63 171.63
## - concave      1   151.93 171.93
## - smoothness   1   152.42 172.42
## - texture      1   195.34 215.34
## 
## Step:  AIC=166.14
## diagnosis ~ radius + texture + perimeter + area + smoothness + 
##     concavity + concave + symmetry + fractal
## 
##               Df Deviance    AIC
## - perimeter    1   146.22 164.22
## - radius       1   146.52 164.52
## - concavity    1   147.25 165.25
## - fractal      1   147.27 165.27
## &lt;none&gt;             146.14 166.14
## - symmetry     1   148.46 166.46
## + compactness  1   146.13 168.13
## - concave      1   151.93 169.93
## - area         1   152.00 170.00
## - smoothness   1   152.45 170.45
## - texture      1   195.48 213.48
## 
## Step:  AIC=164.22
## diagnosis ~ radius + texture + area + smoothness + concavity + 
##     concave + symmetry + fractal
## 
##               Df Deviance    AIC
## - concavity    1   147.28 163.28
## &lt;none&gt;             146.22 164.22
## - fractal      1   148.30 164.30
## - symmetry     1   148.52 164.52
## + perimeter    1   146.14 166.14
## + compactness  1   146.15 166.15
## - radius       1   150.19 166.19
## - concave      1   152.19 168.19
## - area         1   153.35 169.35
## - smoothness   1   153.39 169.39
## - texture      1   195.93 211.93
## 
## Step:  AIC=163.28
## diagnosis ~ radius + texture + area + smoothness + concave + 
##     symmetry + fractal
## 
##               Df Deviance    AIC
## - fractal      1   148.38 162.38
## &lt;none&gt;             147.28 163.28
## - symmetry     1   150.03 164.03
## + concavity    1   146.22 164.22
## + compactness  1   147.24 165.24
## + perimeter    1   147.25 165.25
## - radius       1   153.04 167.04
## - smoothness   1   153.61 167.61
## - area         1   156.64 170.64
## - concave      1   170.51 184.51
## - texture      1   197.40 211.40
## 
## Step:  AIC=162.39
## diagnosis ~ radius + texture + area + smoothness + concave + 
##     symmetry
## 
##               Df Deviance    AIC
## &lt;none&gt;             148.38 162.38
## - symmetry     1   150.68 162.68
## + fractal      1   147.28 163.28
## + compactness  1   147.45 163.45
## + perimeter    1   147.74 163.74
## + concavity    1   148.30 164.30
## - radius       1   153.44 165.44
## - smoothness   1   154.44 166.44
## - area         1   157.38 169.38
## - concave      1   172.31 184.31
## - texture      1   198.83 210.83</code></pre>
<pre class="r"><code># Print the summary of the stepwise model
summary(both)</code></pre>
<pre><code>## 
## Call:
## glm(formula = diagnosis ~ radius + texture + area + smoothness + 
##     concave + symmetry, family = binomial(link = &quot;logit&quot;), data = med)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.94562  -0.15248  -0.04346   0.00366   2.89274  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -8.61085    8.33550  -1.033  0.30159    
## radius      -2.72515    1.17554  -2.318  0.02044 *  
## texture      0.38522    0.06430   5.991 2.09e-09 ***
## area         0.04308    0.01428   3.017  0.00255 ** 
## smoothness  58.37855   23.49622   2.485  0.01297 *  
## concave     73.70154   16.21489   4.545 5.49e-06 ***
## symmetry    15.56212   10.25705   1.517  0.12921    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 751.44  on 568  degrees of freedom
## Residual deviance: 148.39  on 562  degrees of freedom
## AIC: 162.39
## 
## Number of Fisher Scoring iterations: 9</code></pre>
<pre class="r"><code># Select only important variables
med &lt;- med[, c(&quot;diagnosis&quot;,&quot;radius&quot;, &quot;texture&quot;, &quot;area&quot;, &quot;smoothness&quot;, &quot;concave&quot;, &quot;symmetry&quot;)]</code></pre>
<p>After reviewing the stepwise selection, it was decided the following predictors to be used for all model building:</p>
<ol style="list-style-type: decimal">
<li>radius (mean of distances from center to points on the perimeter)</li>
<li>texture (standard deviation of gray-scale values)</li>
<li>area</li>
<li>smoothness (local variation in radius lengths)</li>
<li>concave points (number of concave portions of the contour)</li>
<li>symmetry</li>
</ol>
</div>
<div id="logistic-regression" class="section level3">
<h3>Logistic Regression</h3>
<p>Logistic regression is a parametric statistical learning method, used for classification especially when the outcome is binary. Logistic regression models the probability that a new observation belongs to a particular category. To fit the model, a method called maximum likelihood is used. Below there is an implementation of logistic regression.</p>
<pre class="r"><code># Create a vector with the 70% of the dataset with respect to diagnosis variable
set.seed(1)
inTrain = createDataPartition(med$diagnosis, p = .7)[[1]]


# Assign the 70% of observations to training data
training &lt;- med[inTrain,]

# Assign the remaining 30 % of observations to testing data
testing &lt;- med[-inTrain,]</code></pre>
<pre class="r"><code># Build the model
glm_model &lt;- glm(diagnosis~., data = training, family = binomial)</code></pre>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre class="r"><code>summary (glm_model)</code></pre>
<pre><code>## 
## Call:
## glm(formula = diagnosis ~ ., family = binomial, data = training)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.94085  -0.16420  -0.04401   0.00294   2.54470  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -12.06752    9.72633  -1.241 0.214714    
## radius       -2.33440    1.38723  -1.683 0.092417 .  
## texture       0.37095    0.07015   5.288 1.24e-07 ***
## area          0.04007    0.01689   2.373 0.017641 *  
## smoothness   55.93329   25.21898   2.218 0.026561 *  
## concave      60.09387   17.19606   3.495 0.000475 ***
## symmetry     21.81236   11.67505   1.868 0.061722 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 527.28  on 398  degrees of freedom
## Residual deviance: 118.90  on 392  degrees of freedom
## AIC: 132.9
## 
## Number of Fisher Scoring iterations: 9</code></pre>
<p>By looking at the summary output of the logistic regression model we can see that almost all coefficients are positive, indicating that higher measures mean higher probability of a malignant tumor.</p>
<p>An important step here is to evaluate the predicting ability of the model. Because the model’s predictions are probabilities, we must decide the threshold that will split the two possible outcomes. At first i’ll try the default threshold of 0.5. Below there is a confusion matrix of with predictions using this threshold.</p>
<pre class="r"><code>options(scipen=999)

# Apply the prediction
prediction &lt;- predict(glm_model, newdata= testing, type = &quot;response&quot;)
prediction &lt;- ifelse(prediction &gt; 0.5, &quot;M&quot;, &quot;B&quot;)

# Check the accuracy of the  prediction model by printing the confusion matrix.
print(confusionMatrix(prediction, testing$diagnosis), digits=4)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   B   M
##          B 103   2
##          M   4  61
##                                              
##                Accuracy : 0.9647             
##                  95% CI : (0.9248, 0.9869)   
##     No Information Rate : 0.6294             
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.9248             
##  Mcnemar&#39;s Test P-Value : 0.6831             
##                                              
##             Sensitivity : 0.9626             
##             Specificity : 0.9683             
##          Pos Pred Value : 0.9810             
##          Neg Pred Value : 0.9385             
##              Prevalence : 0.6294             
##          Detection Rate : 0.6059             
##    Detection Prevalence : 0.6176             
##       Balanced Accuracy : 0.9654             
##                                              
##        &#39;Positive&#39; Class : B                  
## </code></pre>
<p>The overall accuracy of the model is 96.47 % (3.53 % error rate). But in this specific case we must distinguish the different types of error. In other words there are two types of error rate, type I &amp; type II errors. In our case these are similar (type II error = 3.74% &amp; type I error = 3.17%). Type I error means that a benign tumor is predicted to be malignant &amp; type II error when a malignant tumor is predicted to be benign. Type II error is more expensive and we must find ways to eliminate it(even if it increases type I error).</p>
<p>Below i increased the threshold to 0.8, which changed the prediction model.</p>
<pre class="r"><code>options(scipen=999)


# Apply the prediction
prediction &lt;- predict(glm_model, newdata= testing, type = &quot;response&quot;)
prediction &lt;- ifelse(prediction &gt; 0.8, &quot;M&quot;, &quot;B&quot;)

# Check the accuracy of the  prediction model by printing the confusion matrix.
print(confusionMatrix(prediction, testing$diagnosis), digits=4)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   B   M
##          B 107   6
##          M   0  57
##                                               
##                Accuracy : 0.9647              
##                  95% CI : (0.9248, 0.9869)    
##     No Information Rate : 0.6294              
##     P-Value [Acc &gt; NIR] : &lt; 0.0000000000000002
##                                               
##                   Kappa : 0.9228              
##  Mcnemar&#39;s Test P-Value : 0.04123             
##                                               
##             Sensitivity : 1.0000              
##             Specificity : 0.9048              
##          Pos Pred Value : 0.9469              
##          Neg Pred Value : 1.0000              
##              Prevalence : 0.6294              
##          Detection Rate : 0.6294              
##    Detection Prevalence : 0.6647              
##       Balanced Accuracy : 0.9524              
##                                               
##        &#39;Positive&#39; Class : B                   
## </code></pre>
<p>Although the overall accuracy of the model remains the same, now the type II error is eliminated but the type I error is increased. In other words, we now have a model that predicts perfectly a malign tumor but it also wrongly predicts some benign tumors as malignant (9.5%).</p>
</div>
<div id="decision-trees" class="section level3">
<h3>Decision Trees</h3>
<p>Decision trees consist of a series of split points, often referred to as nodes. In order to make a prediction using a decision tree, we start at the top of the tree at a single node known as the root node. The root node is a decision or split point, because it places a condition in terms of the value of one of the input features, and based on this decision we know whether to continue on with the left part of the tree or with the right part of the tree. We repeat this process of choosing to go left or right at each inner node that we encounter until we reach one of the leaf nodes. These are the nodes at the base of the tree, which give us a specific value of the output to use as our prediction.</p>
<pre class="r"><code># Create a vector with the 70% of the dataset with respect to diagnosis variable
set.seed(1)
inTrain = createDataPartition(med$diagnosis, p = .7)[[1]]


# Assign the 70% of observations to training data
training &lt;- med[inTrain,]

# Assign the remaining 30 % of observations to testing data
testing &lt;- med[-inTrain,]

# Set seed (in order all results to be fully reproducible) and apply a prediction
#Model with all variables
set.seed(2)
model.all &lt;- train(diagnosis ~ ., method=&quot;rpart&quot;, data = training)

# Apply the prediction
prediction &lt;- predict(model.all, newdata= testing)

# Check the accuracy of the  prediction model by printing the confusion matrix.
print(confusionMatrix(prediction, testing$diagnosis), digits=4)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   B   M
##          B 101   4
##          M   6  59
##                                              
##                Accuracy : 0.9412             
##                  95% CI : (0.8945, 0.9714)   
##     No Information Rate : 0.6294             
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.8747             
##  Mcnemar&#39;s Test P-Value : 0.7518             
##                                              
##             Sensitivity : 0.9439             
##             Specificity : 0.9365             
##          Pos Pred Value : 0.9619             
##          Neg Pred Value : 0.9077             
##              Prevalence : 0.6294             
##          Detection Rate : 0.5941             
##    Detection Prevalence : 0.6176             
##       Balanced Accuracy : 0.9402             
##                                              
##        &#39;Positive&#39; Class : B                  
## </code></pre>
<p>When performing the Decision Trees, as seen from the output, the overall prediction rate is 94.1% (5.9% error rate), which for the specific domain, is relatively low. In particular, the type II error is 5.61% &amp; type I error = 6.35%. The model’s predictive performance is poorer than the previous one (logistic regression).</p>
<p>Now let’s create a classification tree plot of the model.</p>
<pre class="r"><code>library(rpart.plot)

# Plot the Classification Tree
rpart.plot(model.all$finalModel, main = &quot;Classification Tree of tumor type prediction&quot;)</code></pre>
<p><img src="/post/2018-02-19-predict-using-classification-methods_files/figure-html/Decision%20Tree%20Plot-1.png" width="672" /></p>
<p>From the plot above, we can assume that concave and texture are the most import important predictors for tumor type (splits on the classification trees).</p>
</div>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<p>Finally, after building various models using different algorithms, the logistic regression model is chosen based on it’s performance (details on the table below).</p>
<table>
<thead>
<tr class="header">
<th align="center">Prediction model</th>
<th align="center">Overall Error rate</th>
<th align="center">Type I error</th>
<th align="center">Type II error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Logistic regression</td>
<td align="center">3.5 %</td>
<td align="center">9.5 %</td>
<td align="center">0 %</td>
</tr>
<tr class="even">
<td align="center">Decision Trees</td>
<td align="center">5.9 %</td>
<td align="center">5.6 %</td>
<td align="center">6.35 %</td>
</tr>
</tbody>
</table>
<p>In particular, especially after adjusting the threshold, it eliminated the type II error (wrongly predict malignant tumors as benign). This is really important in this specific problem.</p>
<p>As expected parametric methods, such as logistic regression, are performing better in this case, where we have a small dataset (569 observations).</p>
<p>While our analysis is an interesting step it is based on a limited sample of cases. A larger sample of cases, would probably lead us to a better classification model.</p>
</div>

                </section>
            </article>

            
                <a class="twitter" href="https://twitter.com/intent/tweet?text=%2fpost%2fpredict-using-classification-methods%2f - Predict%20using%20classification%20methods by @your_twitter_id"><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

            

            

            

            <footer id="footer">
    
        <div id="social">

	
	
    <a class="symbol" href="https://github.com/mantoniou">
        <i class="fa fa-github-square"></i>
    </a>
    
    <a class="symbol" href="https://www.linkedin.com/in/manos-antoniou-a558001b">
        <i class="fa fa-linkedin-square"></i>
    </a>
    
    <a class="symbol" href="https://twitter.com/mantoniou1">
        <i class="fa fa-twitter-square"></i>
    </a>
    


</div>

    
    <p class="small">
    
       © Copyright 2018 Manos Antoniou 
    
    </p>
</footer>

        </section>

        <script src="/js/jquery-3.3.1.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




  
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-116714552-1', 'auto');
ga('send', 'pageview');
</script>





    </body>
</html>
