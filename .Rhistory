myft <- regulartable(
head(mtcars),
col_keys = c("am", "carb", "gear", "mpg", "drat" ))
myft <- theme_vanilla(myft)
myft
library(flextable)
myft <- regulartable(
head(mtcars),
col_keys = c("am", "carb", "gear", "mpg", "drat" ))
myft <- theme_vanilla(myft)
myft
myft <- merge_v(myft, j = c("am", "carb") )
myft
myft <- set_header_labels( myft, carb = "# carb." )
myft <- width(myft, width = .75) # set width of all columns to .75 in
myft
myft <- autofit(myft)
myft
myft <- autofit(myft)
myft
myft <- italic(myft, j = 1)
myft <- bg(myft, bg = "#C90000", part = "header")
myft <- color(myft, color = "white", part = "header")
myft
myft <- color(myft, ~ drat > 3.5, ~ drat, color = "red")
myft <- bold(myft, ~ drat > 3.5, ~ drat, bold = TRUE)
myft <- autofit(myft)
myft
typology
library(flextable)
myft <- regulartable(
head(mtcars),
col_keys = c("am", "carb", "gear", "mpg", "drat" ))
myft <- theme_vanilla(myft)
myft
myft <- merge_v(myft, j = c("am", "carb") )
myft
myft <- set_header_labels( myft, carb = "# carb." )
myft <- width(myft, width = .75) # set width of all columns to .75 in
myft
myft <- autofit(myft)
myft
myft <- italic(myft, j = 1)
myft <- bg(myft, bg = "#C90000", part = "header")
myft <- color(myft, color = "white", part = "header")
myft
myft <- color(myft, ~ drat > 3.5, ~ drat, color = "red")
myft <- bold(myft, ~ drat > 3.5, ~ drat, bold = TRUE)
myft <- autofit(myft)
myft
plot(iris$Sepal.Length, iris$Petal.Length)
library(forecast)
iris
View(iris)
iris$Sepal.Length
plot(iris$Petal.Length, iris$Petal.Width)
library(tidyverse)
iris %>% ggplot() + geom_point(aes(Sepal.Length, Sepal.Width))
iris %>% ggplot() + geom_point(aes(Sepal.Length, Sepal.Width, color = Species))
iris %>% ggplot() + geom_point(aes(Petal.Width, Petal.Length, color = Species))
iris %>% ggplot() + geom_point(aes(Petal.Width, Petal.Length, color = Species)) + geom_tile("Τα λουλούδια του γραφήματος")
iris %>% ggplot() + geom_point(aes(Petal.Width, Petal.Length, color = Species)) + geom_title("Τα λουλούδια του γραφήματος")
iris %>% ggplot() + geom_point(aes(Petal.Width, Petal.Length, color = Species)) + ggtitle("Τα λουλούδια του γραφήματος")
iris %>% ggplot() + geom_point(aes(Petal.Width, Petal.Length, color = Species)) + ggtitle("Τα λουλούδια του γραφήματος (ΔΗΜΗΤΡΑ ΑΝΤΩΝΙΟΥ)")
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
install.packages("shiny")
blogdown:::serve_site()
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
# Libraries
library(readr)
library(tidyverse)
library(stringr)
library(tidytext)
library(lubridate)
library(wordcloud)
library(topicmodels)
library(tm)
library(stopwords)
library(quanteda)
library(ggthemes)
# Insert data
songs <- read_csv("./data/songs.csv")
songs <- read_csv("/Users/manos/Onedrive/Projects/R/All_Projects/Songs_Lyrics/data/songdata.csv")
# DATA CLEANSING
## Filter data, handle missing values
# Keep songs with 10 or more characters in the lyrics
songs <-
songs %>%
filter(str_length(lyrics) > 10)
View(songs)
# Libraries
library(readr)
library(tidyverse)
library(stringr)
library(tidytext)
library(lubridate)
library(wordcloud)
library(topicmodels)
library(tm)
library(stopwords)
library(quanteda)
library(ggthemes)
# Insert data
songs <- read_csv("/Users/manos/Onedrive/Projects/R/Blog/data/songs.csv")
# DATA CLEANSING
## Filter data, handle missing values
# Keep songs with 10 or more characters in the lyrics
songs <-
songs %>%
filter(str_length(lyrics) > 10)
# Detect the language of the song
library(cld3)
songs$lang <- detect_language(songs$lyrics)
# Filter the songs that
songs <-
songs %>%
filter(lang == "en" & is.na(genre) == FALSE & year >= 1970)
songs$characters <- str_count(songs$lyrics)
## _text cleaning
# Create a vector with stopwords
stopwords <- c(stopwords())
# Clean text
songs$lyrics <- tolower(songs$lyrics)
songs$lyrics <- removePunctuation(songs$lyrics)
songs$lyrics <- removeNumbers(songs$lyrics)
songs$lyrics <- stripWhitespace(songs$lyrics)
songs$lyrics <- removeWords(songs$lyrics, stopwords)
songs$lyrics <- stemDocument(songs$lyrics)
# Save processed data for future use
saveRDS(songs, file = "/Users/manos/OneDrive/Projects/R/All_Projects/Songs_Lyrics/data/cleaned_data.RDS")
## _Insert processed dataset
songs <- readRDS(file = "/Users/manos/OneDrive/Projects/R/All_Projects/Songs_Lyrics/data/cleaned_data.RDS")
# Build the model
glm_model <- glm(diagnosis~., data = training, family = binomial)
# Create a vector with the 70% of the dataset with respect to diagnosis variable
set.seed(1)
inTrain = createDataPartition(med$diagnosis, p = .7)[[1]]
# Load Libraries
library(dplyr)
library(tidyr)
# library(xda)
library(corrgram)
library(ggplot2)
library(ggthemes)
library(cluster)
library(caret)
# Insert dataset into R
med <- read.table("/Users/manos/Onedrive/Projects/R/Blogdown/data/cancer.txt", sep=",", header = TRUE)
# Discard the id column as it will not be used in any of the analysis below
med <- med[, 2:12]
# change the name of the first column to diagnosis
colnames(med)[1] <- "diagnosis"
# Create a long version of the dataset
med2 <- gather(med, "feature", "n", 2:11)
ggplot(med2)+
geom_boxplot(aes(diagnosis, log(n)))+
facet_wrap(~feature, scales = "free")+
labs(title = "Box-plot of all predictors(log scaled) per tumor type",
subtitle = "tumor can be either malignant -M- or benign -B-")+
theme_fivethirtyeight()+
theme(axis.title = element_text()) +
ylab("Predictor's log value") +
xlab('')
# Scatterplot matrix of all numeric variables
pairs(~., data = med[, sapply(med, is.numeric)], main = "Scatterplot Matrix of variables")
library(corrplot)
# Plot correlogram of numeric variables
corrplot(cor(med[,2:11]), type="lower", tl.srt = 90)
library(MASS)
# Create a logistic regression model
glm <- glm(diagnosis ~ ., family=binomial(link='logit'), data = med)
# Run the stepwise regression
both <- stepAIC(glm, direction = "both")
# Print the summary of the stepwise model
summary(both)
# Select only important variables
med <- med[, c("diagnosis","radius", "texture", "area", "smoothness", "concave", "symmetry")]
# Create a vector with the 70% of the dataset with respect to diagnosis variable
set.seed(1)
inTrain = createDataPartition(med$diagnosis, p = .7)[[1]]
# Assign the 70% of observations to training data
training <- med[inTrain,]
# Assign the remaining 30 % of observations to testing data
testing <- med[-inTrain,]
# Build the model
glm_model <- glm(diagnosis~., data = training, family = binomial)
summary (glm_model)
options(scipen=999)
# Apply the prediction
prediction <- predict(glm_model, newdata= testing, type = "response")
prediction <- ifelse(prediction > 0.5, "M", "B")
# Check the accuracy of the  prediction model by printing the confusion matrix.
print(confusionMatrix(prediction, testing$diagnosis), digits=4)
testing$diagnosis
# Check the accuracy of the  prediction model by printing the confusion matrix.
print(confusionMatrix(as.factor(prediction), testing$diagnosis), digits=4)
options(scipen=999)
# Apply the prediction
prediction <- predict(glm_model, newdata= testing, type = "response")
prediction <- ifelse(prediction > 0.8, "M", "B")
# Check the accuracy of the  prediction model by printing the confusion matrix.
print(confusionMatrix(prediction, testing$diagnosis), digits=4)
# Check the accuracy of the  prediction model by printing the confusion matrix.
print(confusionMatrix(as.factor(prediction), testing$diagnosis), digits=4)
# Create a vector with the 70% of the dataset with respect to diagnosis variable
set.seed(1)
inTrain = createDataPartition(med$diagnosis, p = .7)[[1]]
# Assign the 70% of observations to training data
training <- med[inTrain,]
# Assign the remaining 30 % of observations to testing data
testing <- med[-inTrain,]
# Set seed (in order all results to be fully reproducible) and apply a prediction
#Model with all variables
set.seed(2)
model.all <- train(diagnosis ~ ., method="rpart", data = training)
# Apply the prediction
prediction <- predict(model.all, newdata= testing)
# Check the accuracy of the  prediction model by printing the confusion matrix.
print(confusionMatrix(prediction, testing$diagnosis), digits=4)
library(rpart.plot)
# Plot the Classification Tree
rpart.plot(model.all$finalModel, main = "Classification Tree of tumor type prediction")
blogdown:::serve_site()
blogdown:::new_post_addin()
library(tidyverse)
library(plotly)
library(DT)
library(kableExtra)
library(knitr)
theme_set(theme_minimal())
yearly_tag <- read_csv("https://gist.githubusercontent.com/dgrtwo/a30d99baa9b7bfc9f2440b355ddd1f75/raw/700ab5bb0b5f8f5a14377f5103dbe921d4238216/by_tag_year.csv")
kable(head(yearly_tag)) %>%
kable_styling()
# Add fraction column
yearly_tag <-
yearly_tag %>%
mutate(fraction = round(number/year_total, 4))
# Print the new table
kable(head(yearly_tag)) %>%
kable_styling()
# Get the six largest tags
programming_lang <- c("r", "python", "c#", "java", "JavaScript", "php", "c++", "ruby")
yearly_top <-
yearly_tag %>%
filter(tag %in% programming_lang)
d_ends <-
yearly_top %>%
group_by(tag) %>%
slice(n()) %>%
pull(fraction)
d_ends[5] <- 0.06
d_ends[7] <- 0.03
d_labels <-
yearly_top %>%
group_by(tag) %>%
slice(n()) %>%
pull(tag)
# Filter for the six largest tags
ggplot(yearly_top) +
geom_line(aes(x = year, y = fraction, color = tag), size = 1.5, alpha = .8) +
geom_point(aes(x = year, y = fraction, color = tag), size = 2) +
scale_x_continuous(expand = c(0, 0), breaks = c(2008:2018)) +
scale_y_continuous(labels = scales::percent, breaks = c(0, .025, .05, .075, .1, .125), sec.axis = sec_axis(~ ., breaks = d_ends, labels = d_labels)) +
labs(title = "Fraction of total questions per year in Stack Overflow",
subtitle = "for top programming languages",
x = "",
y = "Fraction of total queries in the year") +
theme(legend.position = "none")
yearly_tag %>%
group_by(year) %>%
summarise(year_total = first(year_total)) %>%
filter(year <= 2017) %>%
ggplot() +
geom_line(aes(year, year_total), color = "steelblue", size = 1.5, alpha = .5 ) +
geom_point(aes(year, year_total), color = "steelblue", size = 1.5) +
scale_x_continuous(breaks = c(2008:2017)) +
labs(title = "Total number of questions in Stack overflow per year",
x = "",
y = "Num. of questions")
library(forecast)
library(sweep)
# Get tags for top programming languages
programming_lang <- c("r", "python", "c#", "java", "JavaScript", "php", "c++", "ruby")
# Create the dataset
yearly_nest <-
yearly_tag  %>%
filter(tag %in% programming_lang) %>%
arrange(tag, year) %>%
select(tag, fraction) %>%
group_by(tag) %>%
nest(.key = "data.tbl") %>% # nest it
mutate(data.ts = map(.x    = data.tbl, #create ts object
.f    = ts,
start = 2008)
) %>%
mutate(fit_ets = map(data.ts, ets)) %>%
mutate(summary_ets = map(fit_ets, summary)) %>%
mutate(mape_ets = map(summary_ets, 5)) %>%
mutate(fit.arima = map(data.ts, auto.arima)) %>%
mutate(summary_arima = map(fit.arima, summary)) %>%
mutate(mape_arima = map(summary_arima, 5)) %>%
mutate(final_model = if_else(as.numeric(mape_arima) <= as.numeric(mape_ets), fit.arima, fit_ets)) %>%
mutate(predict = map(final_model, forecast, h = 5)) %>%
mutate(sweep = map(predict, sw_sweep)) %>%
unnest(sweep) %>%
mutate(fraction = if_else(fraction < 0, 0, fraction))
yearly_tag  %>%
filter(tag %in% programming_lang) %>%
arrange(tag, year) %>%
select(tag, fraction) %>%
group_by(tag) %>%
nest(.key = "data.tbl") %>% # nest it
mutate(data.ts = map(.x    = data.tbl, #create ts object
.f    = ts,
start = 2008)
) %>%
mutate(fit_ets = map(data.ts, ets)) %>%
mutate(summary_ets = map(fit_ets, summary)) %>%
mutate(mape_ets = map(summary_ets, 5)) %>%
mutate(fit.arima = map(data.ts, auto.arima)) %>%
mutate(summary_arima = map(fit.arima, summary)) %>%
mutate(mape_arima = map(summary_arima, 5)) %>%
select(tag, mape_arima, mape_ets) %>%
mutate(mape_arima = round(as.numeric(mape_arima), 2),
mape_ets = round(as.numeric(mape_ets), 2)) %>%
kable() %>%
kable_styling()
filter(yearly_nest, key == "forecast") %>%
top_n(15) %>%
kable() %>%
kable_styling()
d_ends <- yearly_nest %>%
group_by(tag) %>%
slice(n()) %>%
pull(fraction)
d_ends[5] <- 0.005
d_labels <- yearly_nest %>%
group_by(tag) %>%
slice(n()) %>%
pull(tag)
# Create the plot
yearly_nest %>%
ggplot() +
theme_minimal() +
geom_line(aes(x = index, y = fraction, color = tag), size = 1.5, alpha = .8) +
geom_point(aes(x = index, y = fraction, color = tag, shape = key ), size = 2) +
scale_x_continuous(expand = c(0, 0), breaks = c(2008:2024)) +
geom_rect(data=data.frame(xmin = 2018, xmax = Inf, ymin = -Inf, ymax = Inf),
aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), fill="steelblue", alpha=0.2) +
geom_text(aes(x = 2019, y = 0.15, label = "Prediction", fill = 1), nudge_x = 1.5, colour = "white", size = 5) +
scale_y_continuous(labels = scales::percent,  sec.axis = sec_axis(~ ., breaks = d_ends, labels = d_labels)) +
labs(title = "Predicting future fraction of total questions per year in Stack Overflow",
subtitle = "for top programming languages",
x = "",
y = "Fraction of total queries in the year") +
theme(legend.position = "none")
blogdown:::serve_site()
blogdown:::serve_site()
library(forecast)
library(sweep)
# Get tags for top programming languages
programming_lang <- c("r", "python", "c#", "java", "JavaScript", "php", "c++", "ruby")
# Create the dataset
yearly_nest <-
yearly_tag  %>%
filter(tag %in% programming_lang) %>%
arrange(tag, year) %>%
select(tag, fraction) %>%
group_by(tag) %>%
nest(.key = "data.tbl") %>% # nest it
mutate(data.ts = map(.x    = data.tbl, #create ts object
.f    = ts,
start = 2008)
) %>%
mutate(fit_ets = map(data.ts, ets)) %>%
mutate(summary_ets = map(fit_ets, summary)) %>%
mutate(mape_ets = map(summary_ets, 5)) %>%
mutate(fit.arima = map(data.ts, auto.arima)) %>%
mutate(summary_arima = map(fit.arima, summary)) %>%
mutate(mape_arima = map(summary_arima, 5)) %>%
mutate(final_model = if_else(as.numeric(mape_arima) <= as.numeric(mape_ets), fit.arima, fit_ets)) %>%
mutate(predict = map(final_model, forecast, h = 5)) %>%
mutate(sweep = map(predict, sw_sweep)) %>%
unnest(sweep) %>%
mutate(fraction = if_else(fraction < 0, 0, fraction))
library(tidyverse)
library(plotly)
library(DT)
library(kableExtra)
library(knitr)
theme_set(theme_minimal())
yearly_tag <- read_csv("https://gist.githubusercontent.com/dgrtwo/a30d99baa9b7bfc9f2440b355ddd1f75/raw/700ab5bb0b5f8f5a14377f5103dbe921d4238216/by_tag_year.csv")
kable(head(yearly_tag)) %>%
kable_styling()
# Add fraction column
yearly_tag <-
yearly_tag %>%
mutate(fraction = round(number/year_total, 4))
# Print the new table
kable(head(yearly_tag)) %>%
kable_styling()
# Get the six largest tags
programming_lang <- c("r", "python", "c#", "java", "JavaScript", "php", "c++", "ruby")
yearly_top <-
yearly_tag %>%
filter(tag %in% programming_lang)
d_ends <-
yearly_top %>%
group_by(tag) %>%
slice(n()) %>%
pull(fraction)
d_ends[5] <- 0.06
d_ends[7] <- 0.03
d_labels <-
yearly_top %>%
group_by(tag) %>%
slice(n()) %>%
pull(tag)
# Filter for the six largest tags
ggplot(yearly_top) +
geom_line(aes(x = year, y = fraction, color = tag), size = 1.5, alpha = .8) +
geom_point(aes(x = year, y = fraction, color = tag), size = 2) +
scale_x_continuous(expand = c(0, 0), breaks = c(2008:2018)) +
scale_y_continuous(labels = scales::percent, breaks = c(0, .025, .05, .075, .1, .125), sec.axis = sec_axis(~ ., breaks = d_ends, labels = d_labels)) +
labs(title = "Fraction of total questions per year in Stack Overflow",
subtitle = "for top programming languages",
x = "",
y = "Fraction of total queries in the year") +
theme(legend.position = "none")
yearly_tag %>%
group_by(year) %>%
summarise(year_total = first(year_total)) %>%
filter(year <= 2017) %>%
ggplot() +
geom_line(aes(year, year_total), color = "steelblue", size = 1.5, alpha = .5 ) +
geom_point(aes(year, year_total), color = "steelblue", size = 1.5) +
scale_x_continuous(breaks = c(2008:2017)) +
labs(title = "Total number of questions in Stack overflow per year",
x = "",
y = "Num. of questions")
library(forecast)
library(sweep)
# Get tags for top programming languages
programming_lang <- c("r", "python", "c#", "java", "JavaScript", "php", "c++", "ruby")
# Create the dataset
yearly_nest <-
yearly_tag  %>%
filter(tag %in% programming_lang) %>%
arrange(tag, year) %>%
select(tag, fraction) %>%
group_by(tag) %>%
nest(.key = "data.tbl") %>% # nest it
mutate(data.ts = map(.x    = data.tbl, #create ts object
.f    = ts,
start = 2008)
) %>%
mutate(fit_ets = map(data.ts, ets)) %>%
mutate(summary_ets = map(fit_ets, summary)) %>%
mutate(mape_ets = map(summary_ets, 5)) %>%
mutate(fit.arima = map(data.ts, auto.arima)) %>%
mutate(summary_arima = map(fit.arima, summary)) %>%
mutate(mape_arima = map(summary_arima, 5)) %>%
mutate(final_model = if_else(as.numeric(mape_arima) <= as.numeric(mape_ets), fit.arima, fit_ets)) %>%
mutate(predict = map(final_model, forecast, h = 5)) %>%
mutate(sweep = map(predict, sw_sweep)) %>%
unnest(sweep) %>%
mutate(fraction = if_else(fraction < 0, 0, fraction))
table_a <-
yearly_tag  %>%
filter(tag %in% programming_lang) %>%
arrange(tag, year) %>%
select(tag, fraction) %>%
group_by(tag) %>%
nest(.key = "data.tbl") %>% # nest it
mutate(data.ts = map(.x    = data.tbl, #create ts object
.f    = ts,
start = 2008)
) %>%
mutate(fit_ets = map(data.ts, ets)) %>%
mutate(summary_ets = map(fit_ets, summary)) %>%
mutate(mape_ets = map(summary_ets, 5)) %>%
mutate(fit.arima = map(data.ts, auto.arima)) %>%
mutate(summary_arima = map(fit.arima, summary)) %>%
mutate(mape_arima = map(summary_arima, 5)) %>%
select(tag, mape_arima, mape_ets) %>%
mutate(mape_arima = round(as.numeric(mape_arima), 2),
mape_ets = round(as.numeric(mape_ets), 2))
table_a%>%
kable() %>%
kable_styling()
blogdown:::serve_site()
